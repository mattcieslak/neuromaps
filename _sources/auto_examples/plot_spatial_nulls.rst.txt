
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_spatial_nulls.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_spatial_nulls.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_spatial_nulls.py:


Using spatial null models
=========================

This example demonstrates how to use spatial null models in
:mod:`neuromaps.nulls` to test the correlation between two brain
annotations.

.. GENERATED FROM PYTHON SOURCE LINES 12-30

The brain—and most features derived from it—is spatially autocorrelated, and
therefore when making comparisons between brain features we need to account
for this spatial autocorrelation.

Enter: spatial null models.

Spatial null models need to be used whenever you're comparing brain maps. In
order to demonstrate how use them in ``neuromaps`` we need two
annotations to compare. We'll use the first principal component of cognitive
terms from NeuroSynth (Yarkoni et al., 2011, Nat Methods) and the first
principal component of gene expression across the brain (from the Allen Human
Brain Atlas).

Note that we pass `return_single=True` to
:func:`neuromaps.datasets.fetch_annotation` so that the returned data are
a list of filepaths rather than the default dictionary format. (This only
works since we know that there is only one annotation matching our query; a
dictionary will always be returned if multiple annotations match our query.)

.. GENERATED FROM PYTHON SOURCE LINES 30-37

.. code-block:: default


    from neuromaps import datasets
    nsynth = datasets.fetch_annotation(source='neurosynth', return_single=True)
    genepc = datasets.fetch_annotation(desc='genepc1', return_single=True)
    print('Neurosynth: ', nsynth)
    print('Gene PC1: ', genepc)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading data from https://files.osf.io/v1/resources/4mw3a/providers/osfstorage/60c22953f3ce9401fa24e651 ...
     ...done. (1 seconds, 0 min)
    Neurosynth:  /home/runner/neuromaps-data/annotations/neurosynth/cogpc1/MNI152/source-neurosynth_desc-cogpc1_space-MNI152_res-2mm_feature.nii.gz
    Gene PC1:  ['/home/runner/neuromaps-data/annotations/abagen/genepc1/fsaverage/source-abagen_desc-genepc1_space-fsaverage_den-10k_hemi-L_feature.func.gii', '/home/runner/neuromaps-data/annotations/abagen/genepc1/fsaverage/source-abagen_desc-genepc1_space-fsaverage_den-10k_hemi-R_feature.func.gii']




.. GENERATED FROM PYTHON SOURCE LINES 38-46

These annotations are in different spaces so we first need to resample them
to the same space. Here, we'll choose to resample them to the 'fsaverage'
surface with a '10k' resolution (approx 10k vertices per hemisphere). Note
that the `genepc1` is already in this space so no resampling will be
performed for those data. (We could alternatively specify 'transform_to_trg'
for the `resampling` parameter and achieve the same outcome.)

The data returned will always be pre-loaded nibabel image instances:

.. GENERATED FROM PYTHON SOURCE LINES 46-55

.. code-block:: default


    from neuromaps import resampling
    nsynth, genepc = resampling.resample_images(src=nsynth, trg=genepc,
                                                src_space='MNI152',
                                                trg_space='fsaverage',
                                                resampling='transform_to_alt',
                                                alt_spec=('fsaverage', '10k'))
    print(nsynth, genepc)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading data from https://files.osf.io/v1/resources/4mw3a/providers/osfstorage/60b684c03a6df1020ed525f6 ...
     ...done. (1 seconds, 0 min)
    Extracting data from /home/runner/neuromaps-data/529deda7a30dc28b5106317477efbaf2/regfusion.tar.gz..... done.
    (<nibabel.gifti.gifti.GiftiImage object at 0x7fcafd1754d0>, <nibabel.gifti.gifti.GiftiImage object at 0x7fcafd566310>) (<nibabel.gifti.gifti.GiftiImage object at 0x7fcb0cdf0790>, <nibabel.gifti.gifti.GiftiImage object at 0x7fcafd587110>)




.. GENERATED FROM PYTHON SOURCE LINES 56-57

Once the images are resampled we can easily correlate them:

.. GENERATED FROM PYTHON SOURCE LINES 57-62

.. code-block:: default


    from neuromaps import stats
    corr = stats.compare_images(nsynth, genepc)
    print(f'Correlation: r = {corr:.02f}')





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Correlation: r = 0.34




.. GENERATED FROM PYTHON SOURCE LINES 63-74

What if we want to assess the statistical significance of this correlation?
In this case, we can use a null model from the :mod:`neuromaps.nulls` module.

Here, we'll employ the null model proposed in Alexander-Bloch et al., 2018,
*NeuroImage*. We provide one of the maps we're comparing, the space + density
of the map, and the number of permutations we want to generate. The returned
array will have two dimensions, where each row corresponds to a vertex and
each column to a unique permutation.

(Note that we need to pass the loaded data from the provided map to the null
function so we use the :func:`neuromaps.images.load_data` utility.)

.. GENERATED FROM PYTHON SOURCE LINES 74-81

.. code-block:: default


    from neuromaps import images, nulls
    nsynth_data = images.load_data(nsynth)
    rotated = nulls.alexander_bloch(nsynth_data, atlas='fsaverage', density='10k',
                                    n_perm=100, seed=1234)
    print(rotated.shape)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading data from https://files.osf.io/v1/resources/4mw3a/providers/osfstorage/60b684ab9096b7021b63cf6b ...
     ...done. (2 seconds, 0 min)
    Extracting data from /home/runner/neuromaps-data/6e43ea0419f74680d0863fb09ee53700/fsaverage10k.tar.gz..... done.
    (20484, 100)




.. GENERATED FROM PYTHON SOURCE LINES 82-90

We can supply the generated null array to the
:func:`neuromaps.stats.compare_images` function and it will be used to
generate a non-parameteric p-value. The function assumes that the array
provided to the `nulls` parameter corresponds to the *first* dataset passed
to the function (i.e., `nsynth`).

Note that the correlation remains identical to that above but the p-value is
now returned as well:

.. GENERATED FROM PYTHON SOURCE LINES 90-94

.. code-block:: default


    corr, pval = stats.compare_images(nsynth, genepc, nulls=rotated)
    print(f'Correlation: r = {corr:.02f}, p = {pval:.04f}')





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Correlation: r = 0.34, p = 0.1782




.. GENERATED FROM PYTHON SOURCE LINES 95-98

There are a number of different null functions that can be used to generate
null maps; they have (nearly) identical function signatures, so refer to the
:ref:`API reference <ref_nulls>` for more information.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  7.337 seconds)


.. _sphx_glr_download_auto_examples_plot_spatial_nulls.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_spatial_nulls.py <plot_spatial_nulls.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_spatial_nulls.ipynb <plot_spatial_nulls.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
